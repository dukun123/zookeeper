1.Zookeeper是Hadoop的一个子项目，它是分布式系统中的协调系统，它是集群的管理者(例如kafka集群)，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。
最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户



最重要的是 Zoopkeeper 提供了一套很好的分布式集群管理的机制，就是它这种基于层次型的目录树的数据结构，
并对树中的节点进行有效管理，从而可以设计出多种多样的分布式的数据管理模型，



2. zookeeper 也是一个文件系统，Zookeeper的数据存储采用的是结构化存储，结构化存储是没有文件和目录的概念，
   里边的目录和文件被抽象成了节点（node），zookeeper里可以称为znode


3: zookeeper的客户端一般有两种，一个是终端，一个是API；

4. znode 有四种类型：
 （1）PERSISTENT-持久化目录节点 ，客户端与zookeeper断开连接后，该节点依旧存在
 （2）PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点，客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号
  (3）EPHEMERAL-临时目录节点,客户端与zookeeper断开连接后，该节点被删除
  (4) EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点,客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号

5：zookeeper配置模式：一般有两种单机模式（standalone）和集群模式（cluster）

6. zookeeper数据复制：Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：

                    1、容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；

                    2、提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力；

                    3、提高性能：让客户端本地访问就近的节点，提高用户访问速度。

7：zookeeper集群客户端读写模式：zookeeper采用的是Write on Master，对数据的修改提交给指定的节点。
                             读无此限制，可以读取任何一个节点。 让客户端本地访问就近的节点，提高用户访问速度。

8：Zookeeper设计目的

  1.最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。

  2.可靠性：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。

  3.实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，
    Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。

  4.等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。

  5.原子性：更新只能成功或者失败，没有中间状态。

  6.顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。





9: zookeeper集群模式角色说明：
   （1）领导者(leader):Leader作为整个Zookeeper集群的主节点，事务请求的唯一调度和处理者，保证集群事务处理的顺序性，集群内部各服务器的调度者，处理客户端非事务性请求（读取数据）。
                      维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型 leader主要从learner接受4中类型的消息：
                      a. PING 消息是指Learner的心跳信息；
                      b. REQUEST消息是Follower发送的信息，包括写请求及同步请求；
                      c. ACK消息是 Follower的对leader提议的回复，超过半数的Follower通过，则commit该提议；
                      d. REVALIDATE消息是用来延长SESSION有效时间。
   （2）跟随者(follower): 处理客户端非事务性请求（读取数据），转发事务请求给Leader服务器，参与事务请求Proposal的投票， 参与Leader选举投票。
                        Follower的消息循环处理如下几种来自Leader的消息：
                        a.PING消息： 心跳消息；
                        b .PROPOSAL消息：Leader发起的提案，要求Follower投票；
                        c .COMMIT消息：服务器端最新一次提案的信息；
                        d .UPTODATE消息：表明同步完成；
                        e .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；
                        f.SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。


   （3）观察者(observer)(可选): Observer充当观察者角色，观察Zookeeper集群的最新状态变化并将这些状态同步过来，
                        其对于非事务请求可以进行独立处理，对于事务请求，则会转发给Leader服务器进行处理。
                        Observer不会参与任何形式的投票，包括事务请求Proposal的投票和Leader选举投票

10.Zookeeper集群下Server工作状态：
    每个Server在工作过程中有三种状态：
    1. LOOKING：当前Server不知道leader是谁，正在搜寻
    2. LEADING：当前Server即为选举出来的leader
    3. FOLLOWING：leader已经选举出来，当前Server与之同步



11. Zookeeper工作原理
    上面介绍了很多zookeeper的机制和特点，下面介绍一下zookeeper到底怎么工作：
   (1)基本概念（其实都是说的一个意思，看看哪个意思你能明白）：
    a. Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步（最终一致性）。实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast，全称为：原子消息广播协议）
    b. zookeeper主要是根据ZAB协议是实现分布式系统数据一致性。
    c. zookeeper根据ZAB协议建立了zookeeper集群中数据的同步。这里所说的主从系统架构模型是指，在zookeeper集群中，只有一台leader负责处理外部客户端的事物请求(或写操作)，
       然后leader服务器将客户端的写操作数据同步到所有的follower节点中。
    d. ZAB的协议核心是在整个zookeeper集群中只有一个节点即Leader将客户端的写操作转化为事物(或提议proposal)。
       Leader节点在数据写完之后，将向所有的follower节点发送数据广播请求(或数据复制)，等待所有的follower节点反馈。在ZAB协议中，
       只要超过半数follower节点反馈OK，Leader节点就会向所有的follower服务器发送commit消息。即将leader节点上的数据同步到follower节点之上。

   （2）ZAB特点
    a. 可靠提交(Reliable delivery) -如果一个事务 A 被一个server提交(committed)了，那么它最终一定会被所有的server提交;
    b. 全局有序(Total order) - 假设有A、B两个事务，有一台server先执行A再执行B，那么可以保证所有server上A始终都被在B之前执行,
    c. 因果有序(Causal order) - 如果发送者在事务A提交之后再发送B,那么B必将在A之后执行
    注释：每一个follower节点都会有一个先进先出（FIFO)的队列用来存放收到的事务请求，保证在follower执行事务的顺序，这个队列叫做历史队列(history queue)
   （3）ZXID
        ZooKeeper会为每一个事务生成一个唯一且递增长度为64位的ZXID,ZXID由两部分组成：低32位表示计数器(counter)和高32位的纪元号(epoch)。
        epoch为当前leader在成为leader的时候生成的，且保证会比前一个leader的epoch大
        (实际上当新的leader选举成功后，会拿到当前集群中最大的一个ZXID，并去除这个ZXID的epoch,并将此epoch进行加1操作，作为自己的epoch。)

   （4）ZAB工作模式(这样的模式才能保证数据一致性，ZAB特点)
       1.广播(broadcast)模式（看照片）
         zookeeper中消息广播的具体步骤如下：
         4.1. 客户端发起一个写操作请求
         4.2. Leader服务器将客户端的request请求转化为事物proposql提案，同时为每个proposal分配一个全局唯一的ID，即ZXID。
         4.3. leader服务器与每个follower之间都有一个队列，leader将消息发送到该队列
         4.4. follower机器从队列中取出消息处理完(写入本地事物日志中)毕后，向leader服务器发送ACK确认。
         4.5. leader服务器收到半数以上的follower的ACK后，即认为可以发送commit
         4.6. leader向所有的follower服务器发送commit消息。
      大白话解释一下（个人理解）：
          一个客户端的写请求进来之后，leader 会为每个客户端的写请求包装成事务，广播模式需要保证proposal被按顺序处理，因此zk采用了递增的事务id号(zxid)来保证。
          所有的提议(proposal)都在被提出的时候加上了zxid。leader 会为该事务生成一个 Proposal,进行广播，leader 会为每一个 Follower服务器分配一个单独的FIFO 队列，
          然后把 Proposal 放到队列中，每一个 Follower 收到 该 Proposal 之后会把它持久到磁盘上，当完全写入之后，发一个 ACK 给leader，
          我们的leader 也不傻，收到超过半数机器的ack之后，他自己把自己机器上 Proposal 提交一下，同时开始广播 commit,每一个 Follower 收到 commit 之后，完成各自的事务提交。
          注释：1. zookeeper采用ZAB协议的核心就是只要有一台服务器提交了proposal，就要确保所有的服务器最终都能正确提交proposal，可靠提交(Reliable delivery)
               2. leader服务器与每个follower之间都有一个单独的队列进行收发消息，使用队列消息可以做到异步解耦。
                  leader和follower之间只要往队列中发送了消息即可。如果使用同步方式容易引起阻塞。性能上要下降很多。

       2. 恢复(recovery)模式
           当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式,大体上有这么几步：
          a. 选举(一般为集群中拥有最大ZXID的节点)
          zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是leader服务器接受写请求，即使是follower服务器接受到客户端的请求，也会转发到leader服务器进行处理。
          如果leader服务器发生崩溃，则zab协议要求zookeeper集群进行崩溃恢复和leader服务器选举。
          ZAB协议崩溃恢复要求满足如下2个要求：
          3.1. 确保已经被leader提交的proposal必须最终被所有的follower服务器提交。
          3.2. 确保丢弃已经被leader出的但是没有被提交的proposal。
          根据上述要求，新选举出来的leader不能包含未提交的proposal，即新选举的leader必须都是已经提交了的proposal的follower服务器节点。同时，新选举的leader节点中含有最高的ZXID。这样做的好处就是可以避免了leader服务器检查proposal的提交和丢弃工作。
          leader服务器发生崩溃时分为如下场景：
          5.1. leader在提出proposal时未提交之前崩溃，则经过崩溃恢复之后，新选举的leader一定不能是刚才的leader。因为这个leader存在未提交的proposal。
          5.2 leader在发送commit消息之后，崩溃。即消息已经发送到队列中。经过崩溃恢复之后，参与选举的follower服务器(刚才崩溃的leader有可能已经恢复运行，也属于follower节点范畴)中有的节点已经是消费了队列中所有的commit消息。即该follower节点将会被选举为最新的leader。剩下动作就是数据同步过程。

          b. 发现（根据选举结果，产生新的leader）
             进入发现阶段，follower与潜在的新leader进行沟通，如果发现超过法定人数的follower同意，
             则潜在的新leader将epoch加1，进入新的纪元。新的leader产生

          c. 数据同步 集群间进行数据同步，保证集群中各个节点的事务一致
              1. 在zookeeper集群中新的leader选举成功之后，leader会将自身的提交的最大proposal的事物ZXID发送给其他的follower节点。
              follower节点会根据leader的消息进行回退或者是数据同步操作。最终目的要保证集群中所有节点的数据副本保持一致。
              数据同步完之后，
              2. zookeeper集群如何保证新选举的leader分配的ZXID是全局唯一呢？这个就要从ZXID的设计谈起。
                2.1 ZXID是一个长度64位的数字，其中低32位是按照数字递增，即每次客户端发起一个proposal,低32位的数字简单加1。
                    高32位是leader周期的epoch编号，至于这个编号如何产生(我也没有搞明白)，每当选举出一个新的leader时，新的leader就从本地事物日志中取出ZXID,
                    然后解析出高32位的epoch编号，进行加1，再将低32位的全部设置为0。这样就保证了每次新选举的leader后，保证了ZXID的唯一性而且是保证递增的。
              3.完成同步后leader通知follower 已经成为uptodate状态
           d.广播
             leader可以接受客户端新的事务请求，将新的事务请求广播给所有的follower。



12. zookeeper 启动流程
          就不讲standalone的启动方式了，毕竟zookeeper主要都是以集群的方式出现的。
          zookeeper服务器端的启动是从QuorumPeerMain类（在org.apache.zookeeper.server.quorum包中）里的main开始的，
          main中会调用类QuorumPeerMain的构造函数，然后调用initializeAndRun函数开始服务器端的初始化。
          在initializeAndRun函数中，首先要解析配置文件，获取相关的启动配置信息到类QuorumPeerConfig中，
          然后根据当前服务器运行在standalone模式还是集群模式下选择相关启动函数，对于集群模式而言是函数runFromConfig。
          该函数通过QuorumPeerConfig类中记录的配置信息设置QuorumPeerMain类中的相关参数，，
          最后通过调用QuorumPeer类中的start函数启动QuorumPeer线程。在QuorumPeer.start函数中，
          首先会通过ZKDatabase类（在org.apache.zookeeper.server包中）的loadDataBase函数从磁盘中的snapshot和log文件中回复数据库以及committedLog，
          然后启动NIOServerCnxn类（在org.apache.zookeeper.server包中）的Factory线程（具体作用不再解释，参见zookeeper线程），
          最后调用startLeaderElection函数初始化LeaderElection，此时会调用createElectionAlgorithm函数，由于当前zookeeper默认支持选举策略3
          （基于TCP的FastElection），因此在createElectionAlgorithm函数中会启动QuorumCnxManager类（在org.apache.zookeeper.server.quorum包中）
          中的listener线程监听用于LeaderElection的端口，并初始化FastLeaderElection类（在org.apache.zookeeper.server.quorum包中），
          FastLeaderElection类构造函数中，会调用starter函数，继而初始化Messenger类（在FastLeaderElection类中），
          初始化Messenger类时会启动WorkerSender和WorkerReceiver线程。在FastLeaderElection类初始化结束后会正式启动QuorumPeer线程，
          此时zookeeper初始化完毕并进入QuorumPeer主线程（run函数）。




